// src/features/pronunciation/components/RecordingStage.tsx
import React, { useRef, useEffect, useState } from "react";
import { motion } from "framer-motion";
import { usePronunciationStore } from "@/store/pronunciationStore";
import { useAudioRecorder } from "@/features/pronunciation/hooks/useAudioRecorder";
import * as styles from "./PronunciationModal.css.ts";
import { Button } from "@/shared/components/Button";
import SpeechRecognition, {
  useSpeechRecognition,
} from "react-speech-recognition";

export function RecordingStage() {
  const {
    setCurrentStage,
    setRecordedAudioBlob,
    currentContext,
    setSttTranscript,
  } = usePronunciationStore();
  const recordingWaveformRef = useRef<HTMLDivElement>(null);

  // react-speech-recognition í›…
  const {
    transcript,
    listening,
    resetTranscript,
    browserSupportsSpeechRecognition,
    isMicrophoneAvailable,
  } = useSpeechRecognition();

  const {
    initializeRecorder,
    startRecording,
    stopRecording,
    pauseRecording,
    cleanup,
    isRecording,
    isPaused,
    recordingTime,
    recordedBlob,
  } = useAudioRecorder();

  const [isInitialized, setIsInitialized] = useState(false);

  // ë¸Œë¼ìš°ì € ì§€ì› ì²´í¬
  useEffect(() => {
    if (!browserSupportsSpeechRecognition) {
      console.warn("ë¸Œë¼ìš°ì €ê°€ ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
    }
    if (!isMicrophoneAvailable) {
      console.warn("ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
    }
  }, [browserSupportsSpeechRecognition, isMicrophoneAvailable]);

  // wavesurfer ì´ˆê¸°í™” STT ì •ë¦¬
  useEffect(() => {
    if (!recordingWaveformRef.current) return;

    initializeRecorder(recordingWaveformRef.current);
    setIsInitialized(true);

    return () => {
      cleanup();
      // STT ì •ë¦¬
      SpeechRecognition.stopListening();
    };
  }, [initializeRecorder, cleanup]);

  // ìë™ìœ¼ë¡œ ë…¹ìŒ ì‹œì‘
  useEffect(() => {
    if (isInitialized && !isRecording) {
      console.log("Attempting to start recording...");
      startRecording().then((success) => {
        if (!success) {
          console.error("Failed to start recording automatically");
        }
      });

      // STT ì‹œì‘
      if (browserSupportsSpeechRecognition) {
        resetTranscript(); // ì´ì „ í…ìŠ¤íŠ¸ ì´ˆê¸°í™”
        SpeechRecognition.startListening({
          continuous: true, // ê³„ì† ë“£ê¸°
          language: "ko-KR", // í•œêµ­ì–´ ì„¤ì •
        });
        console.log("ğŸ¤ STT started listening...");
      }
    }
  }, [
    isInitialized,
    startRecording,
    browserSupportsSpeechRecognition,
    isRecording,
    resetTranscript,
  ]);

  // ë…¹ìŒ ì™„ë£Œ ì²˜ë¦¬
  useEffect(() => {
    if (recordedBlob) {
      setRecordedAudioBlob(recordedBlob);
      setCurrentStage("analyzing");
    }
  }, [recordedBlob, setRecordedAudioBlob, setCurrentStage]);

  const formatTime = (milliseconds: number) => {
    const totalSeconds = Math.floor(milliseconds / 1000);
    const minutes = Math.floor(totalSeconds / 60);
    const seconds = totalSeconds % 60;
    return `${minutes
      .toString()
      .padStart(2, "0")}:${seconds.toString().padStart(2, "0")}`;
  };

  const handleStopRecording = () => {
    stopRecording();

    // STT ì¤‘ì§€
    if (listening) {
      SpeechRecognition.stopListening();
      console.log("ğŸ”´ STT stopped");
    }

    // ìµœì¢… STT ê²°ê³¼ ì¶œë ¥
    console.log("================== STT ìµœì¢… ê²°ê³¼ ==================");
    console.log("ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", transcript || "(ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì—†ìŒ)");
    console.log(
      "ğŸ“– ì›ë³¸ í…ìŠ¤íŠ¸:",
      currentContext?.text || "(ì›ë³¸ í…ìŠ¤íŠ¸ ì—†ìŒ)"
    );

    //ANCHOR âœ… STT ê²°ê³¼ë¥¼ storeì— ì €ì¥
    setSttTranscript(transcript || "");

    // CER ê³„ì‚° (ê°„ë‹¨í•œ ë¹„êµ)
    if (transcript && currentContext?.text) {
      const similarity = calculateSimpleSimilarity(
        currentContext.text,
        transcript
      );
      console.log("âœ… í…ìŠ¤íŠ¸ ìœ ì‚¬ë„(simple):", `${(similarity * 100).toFixed(1)}%`);
    }
    console.log("==================================================");
  };

  // ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
  const calculateSimpleSimilarity = (text1: string, text2: string): number => {
    const clean1 = text1.replace(/\s/g, "").toLowerCase();
    const clean2 = text2.replace(/\s/g, "").toLowerCase();

    let matches = 0;
    const maxLength = Math.max(clean1.length, clean2.length);
    const minLength = Math.min(clean1.length, clean2.length);

    for (let i = 0; i < minLength; i++) {
      if (clean1[i] === clean2[i]) matches++;
    }

    return maxLength > 0 ? matches / maxLength : 0;
  };

  const handlePauseResume = () => {
    pauseRecording();
    if (isPaused) {
      // ì¬ë…¹ìŒ
      if (browserSupportsSpeechRecognition) {
        SpeechRecognition.startListening({
          continuous: true,
          language: "ko-KR",
        });
        console.log("â–¶ï¸ STT resumed");
      }
      console.log("â¸ï¸ true STT paused");
    } else {
      SpeechRecognition.stopListening();
      //ì¼ì‹œì •ì§€ í´ë¦­
      console.log("â¸ï¸ false STT paused");
    }
  };

  return (
    <motion.div
      className={styles.stageContainer}
      initial={{ opacity: 0, y: 20 }}
      animate={{ opacity: 1, y: 0 }}
      exit={{ opacity: 0, y: -20 }}
    >
      <div className={styles.stageHeader}>
        <h2 className={styles.stageTitle}>
          {isPaused ? "â¸ï¸ ë…¹ìŒ ì¼ì‹œì •ì§€" : "ğŸ”´ ë…¹ìŒ ì¤‘..."}
        </h2>
        <p className={styles.stageSubtitle}>ìì—°ìŠ¤ëŸ½ê²Œ ë”°ë¼ ë§í•´ë³´ì„¸ìš”</p>
      </div>
      {/* ì„ íƒí•œ í…ìŠ¤íŠ¸ í‘œì‹œ */}
      <motion.div
        className={styles.textDisplay}
        initial={{ opacity: 0, scale: 0.9 }}
        animate={{ opacity: 1, scale: 1 }}
        transition={{ delay: 0.2 }}
      >
        <p className={styles.choiceText}>"{currentContext?.text}"</p>
      </motion.div>
      {/* ì‹¤ì‹œê°„ íŒŒí˜• í‘œì‹œ */}
      <div className={styles.recordingSection}>
        <div className={styles.waveformContainer}>
          <div
            ref={recordingWaveformRef}
            className={styles.recordingWaveform}
          />
        </div>

        {/* ë…¹ìŒ ì‹œê°„ í‘œì‹œ */}
        <div className={styles.timeDisplay}>
          <span className={styles.recordingTime}>
            â±ï¸ {formatTime(recordingTime)}
          </span>
        </div>
        {/* STT ìƒíƒœ í‘œì‹œ (ë””ë²„ê¹…ìš©) */}
        {browserSupportsSpeechRecognition && (
          <div
            className={styles.sttStatus}
            style={{ marginTop: "10px", fontSize: "12px", color: "#666" }}
          >
            <span>ğŸ™ï¸ STT: {listening ? "ë“£ëŠ” ì¤‘" : "ì¤‘ì§€"}</span>
            {transcript && (
              <div
                style={{
                  marginTop: "5px",
                  padding: "5px",
                  backgroundColor: "#f0f0f0",
                  borderRadius: "4px",
                }}
              >
                ì¸ì‹ ì¤‘: {transcript}
              </div>
            )}
          </div>
        )}
        {/* ë…¹ìŒ ìƒíƒœ ì¸ë””ì¼€ì´í„° */}

        {isPaused ? (
          <div
            className={styles.recordingIndicator}
            style={{ borderColor: "rgba(255, 224, 130, 1)" }}
          >
            <motion.div
              className={styles.recordingDot}
              animate={{
                scale: isPaused ? 1 : [1, 1.2, 1],
                opacity: isPaused ? 0.5 : [0.5, 1, 0.5],
              }}
              transition={{
                duration: 1,
                repeat: isPaused ? 0 : Infinity,
                ease: "easeInOut",
              }}
            />
            <span
              className={styles.recordingStatus}
              style={{ color: "rgba(255, 224, 130, 1)" }}
            >
              ì¼ì‹œì •ì§€ë¨
            </span>
          </div>
        ) : (
          <div className={styles.recordingIndicator}>
            <motion.div
              className={styles.recordingDot}
              animate={{
                scale: isPaused ? 1 : [1, 1.2, 1],
                opacity: isPaused ? 0.5 : [0.5, 1, 0.5],
              }}
              transition={{
                duration: 1,
                repeat: isPaused ? 0 : Infinity,
                ease: "easeInOut",
              }}
            />
            <span className={styles.recordingStatus}>ë…¹ìŒ ì¤‘</span>
          </div>
        )}
      </div>

      {/* ì»¨íŠ¸ë¡¤ ë²„íŠ¼ë“¤ */}
      <div className={styles.recordingControls}>
        <Button
          variant="sub"
          size="small"
          onClick={handlePauseResume}
          className={styles.pauseButton}
          fullWidth
          icon={!isPaused ? "â¸ï¸" : "â–¶ï¸"}
          iconPosition="left"
        >
          {!isPaused ? "ì¼ì‹œì •ì§€" : "ì¬ê°œ"}
        </Button>

        <Button
          variant="main"
          size="small"
          onClick={handleStopRecording}
          className={styles.stopButton}
          fullWidth
          icon={"â¹ï¸"}
          iconPosition="left"
        >
          ë…¹ìŒ ì™„ë£Œ
        </Button>
      </div>

      {/* ì•ˆë‚´ ë©”ì‹œì§€ */}
      <div className={styles.guideSection}>
        <p className={styles.guideText}>
          ğŸ“¢ ë§ˆì´í¬ì— ëŒ€ê³  ëª…í™•í•˜ê²Œ ë°œìŒí•´ì£¼ì„¸ìš”
        </p>
        <p className={styles.guideText}>ìµœëŒ€ 30ì´ˆê¹Œì§€ ë…¹ìŒ ê°€ëŠ¥í•©ë‹ˆë‹¤</p>
      </div>
    </motion.div>
  );
}
