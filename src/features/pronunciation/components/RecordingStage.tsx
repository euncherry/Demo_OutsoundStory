// src/features/pronunciation/components/RecordingStage.tsx
import React, { useRef, useEffect, useState } from "react";
import { motion } from "framer-motion";
import { usePronunciationStore } from "@/store/pronunciationStore";
import { useAudioRecorder } from "@/features/pronunciation/hooks/useAudioRecorder";
import * as modalStyles from "./PronunciationModal.css";
import * as styles from "./RecordingStage.css";
import { Button3D } from "@/shared/components/3DButton";
import { Button } from "@/shared/components/Button";
import useSpeechToText from "@/pages/test/hooks/useSpeechToText";
import micIconLarge from "/assets/ui/decorations/micIcon.png";

export function RecordingStage() {
  const {
    setCurrentStage,
    setRecordedAudioBlob,
    currentContext,
    setSttTranscript,
  } = usePronunciationStore();
  const recordingWaveformRef = useRef<HTMLDivElement>(null);

  const {
    transcript,
    listening,
    startListening,
    stopListening,
    resetTranscript,
    browserSupportsSpeechRecognition,
    isMicrophoneAvailable,
  } = useSpeechToText();

  const {
    initializeRecorder,
    startRecording,
    stopRecording,
    pauseRecording,
    cleanup,
    isRecording,
    isPaused,
    recordingTime,
    recordedBlob,
  } = useAudioRecorder();

  const [isInitialized, setIsInitialized] = useState(false);

  const [isRecordingStarted, setIsRecordingStarted] = useState(false);

  // ë¸Œë¼ìš°ì € ì§€ì› ì²´í¬
  useEffect(() => {
    if (!browserSupportsSpeechRecognition) {
      console.warn("ë¸Œë¼ìš°ì €ê°€ ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.");
    }
    if (!isMicrophoneAvailable) {
      console.warn("ë§ˆì´í¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.");
    }
  }, [browserSupportsSpeechRecognition, isMicrophoneAvailable]);

  // wavesurfer ì´ˆê¸°í™” STT ì •ë¦¬
  useEffect(() => {
    if (!recordingWaveformRef.current) return;

    initializeRecorder(recordingWaveformRef.current);
    setIsInitialized(true);

    return () => {
      cleanup();
      // STT ì •ë¦¬
      // SpeechRecognition.stopListening();
    };
  }, [initializeRecorder, cleanup]);

  // ìë™ìœ¼ë¡œ ë…¹ìŒ ì‹œì‘
  useEffect(() => {
    if (!isRecordingStarted || isRecording || !isInitialized) return;
    console.log("[useEffect] isRecordingStarted", isRecordingStarted);
    if (isInitialized && !isRecording && isRecordingStarted) {
      console.log("[useEffect] Attempting to start recording...");
      console.log("[useEffect] isInitialized", isInitialized);
      console.log("[useEffect] isRecording", isRecording);
      // startRecording().then((success) => {
      //   if (!success) {
      //     console.error("[useEffect] Failed to start recording automatically");
      //   }
      // });
    }
  }, [
    isInitialized,
    startRecording,
    browserSupportsSpeechRecognition,
    isRecording,
    resetTranscript,
    isRecordingStarted,
  ]);

  const handleStartRecording = () => {
    setIsRecordingStarted(true);
    resetTranscript();
    startListening();
  };

  // ë…¹ìŒ ì™„ë£Œ ì²˜ë¦¬
  useEffect(() => {
    if (recordedBlob) {
      setRecordedAudioBlob(recordedBlob);
      setCurrentStage("analyzing");
    }
  }, [recordedBlob, setRecordedAudioBlob, setCurrentStage]);

  const formatTime = (milliseconds: number) => {
    const totalSeconds = Math.floor(milliseconds / 1000);
    const minutes = Math.floor(totalSeconds / 60);
    const seconds = totalSeconds % 60;
    return `${minutes.toString().padStart(2, "0")}:${seconds
      .toString()
      .padStart(2, "0")}`;
  };

  const handleStopRecording = () => {
    stopRecording();

    // STT ì¤‘ì§€
    if (listening) {
      // SpeechRecognition.stopListening();
      stopListening();
      console.log("ğŸ”´ STT stopped");
      console.log("ğŸ”´ STT stopped");
    }

    // ìµœì¢… STT ê²°ê³¼ ì¶œë ¥
    console.log("================== STT ìµœì¢… ê²°ê³¼ ==================");
    console.log("ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:", transcript || "(ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì—†ìŒ)");
    console.log(
      "ğŸ“– ì›ë³¸ í…ìŠ¤íŠ¸:",
      currentContext?.text || "(ì›ë³¸ í…ìŠ¤íŠ¸ ì—†ìŒ)"
    );

    //ANCHOR âœ… STT ê²°ê³¼ë¥¼ storeì— ì €ì¥
    setSttTranscript(transcript || "");

    // CER ê³„ì‚° (ê°„ë‹¨í•œ ë¹„êµ)
    if (transcript && currentContext?.text) {
      const similarity = calculateSimpleSimilarity(
        currentContext.text,
        transcript
      );
      console.log(
        "âœ… í…ìŠ¤íŠ¸ ìœ ì‚¬ë„(simple):",
        `${(similarity * 100).toFixed(1)}%`
      );
    }
    console.log("==================================================");
  };

  // ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜
  const calculateSimpleSimilarity = (text1: string, text2: string): number => {
    const clean1 = text1.replace(/\s/g, "").toLowerCase();
    const clean2 = text2.replace(/\s/g, "").toLowerCase();

    let matches = 0;
    const maxLength = Math.max(clean1.length, clean2.length);
    const minLength = Math.min(clean1.length, clean2.length);

    for (let i = 0; i < minLength; i++) {
      if (clean1[i] === clean2[i]) matches++;
    }

    return maxLength > 0 ? matches / maxLength : 0;
  };

  const handlePauseResume = () => {
    pauseRecording();
    if (listening) {
      stopListening();
      console.log("ğŸ”´ STT stopped");
    } else {
      startListening();
      console.log("â–¶ï¸ STT started");
    }
  };

  return (
    <>
      <motion.div
        className={modalStyles.stageContainer}
        initial={{ opacity: 0, y: 20 }}
        animate={{ opacity: 1, y: 0 }}
        exit={{ opacity: 0, y: -20 }}
      >
        <div className={modalStyles.stageHeader}>
          <h2 className={modalStyles.stageTitle}>
            {!isRecordingStarted
              ? "ë°œìŒ ë…¹ìŒí•˜ê¸°"
              : isPaused
              ? "ë…¹ìŒ ì¼ì‹œì •ì§€"
              : "ë…¹ìŒ ì¤‘..."}
          </h2>
          <p className={modalStyles.stageSubtitle}>
            {!isRecordingStarted
              ? "ì¤€ë¹„ê°€ ë˜ë©´ ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”."
              : "ìì—°ìŠ¤ëŸ½ê²Œ ë”°ë¼ ë§í•´ë³´ì„¸ìš”"}
          </p>
        </div>
        {/* ì„ íƒí•œ í…ìŠ¤íŠ¸ í‘œì‹œ */}
        <motion.div
          className={modalStyles.textDisplay}
          initial={{ opacity: 0, scale: 0.9 }}
          animate={{ opacity: 1, scale: 1 }}
          transition={{ delay: 0.2 }}
        >
          <p className={modalStyles.choiceText}>"{currentContext?.text}"</p>
        </motion.div>

        {/* recording content */}

        {isRecordingStarted ? (
          <>
            <div
              className={styles.recordingContent}
              style={{
                background: `linear-gradient(135deg, rgba(255, 245, 245, 0.4),rgba(255, 223, 245, 0.5), rgba(255, 223, 245, 0.6))`,
              }}
            >
              <div
                className={styles.recordingContentGrid}
                style={{ gridTemplateRows: "3fr 1fr 3fr 1fr 3fr" }}
              >
                {/* ì²« ë²ˆì§¸ ê·¸ë¦¬ë“œ ì•„ì´í…œ - ì§„í­ ê·¸ë˜í”„ 2fr */}
                <div className={styles.recordingContentReadyGridItem}>
                  <div className={styles.waveformContainer}>
                    <div
                      ref={recordingWaveformRef}
                      className={styles.recordingWaveform}
                    />
                  </div>
                </div>
                <div className={styles.recordingContentReadyGridItem}>
                  <div className={styles.timeDisplay}>
                    <span className={styles.recordingTime}>
                      â±ï¸ {formatTime(recordingTime)}
                    </span>
                  </div>
                </div>
                <div className={styles.recordingContentReadyGridItem}>
                  <p>ë…¹ìŒ ì¤‘...</p>
                </div>
              </div>
            </div>
          </>
        ) : (
          <>
            <div className={styles.recordingContent}>
              <div className={styles.recordingContentGrid}>
                {/* ì²« ë²ˆì§¸ ê·¸ë¦¬ë“œ ì•„ì´í…œ - ë§ˆì´í¬ ì•„ì´ì½˜ 3fr */}
                <div className={styles.recordingContentMicGridItem}>
                  <div className={styles.imageContainer}>
                    <img
                      src={micIconLarge}
                      alt="ë§ˆì´í¬ ì•„ì´ì½˜"
                      className={styles.scaledImage} // scale-down ë°©ì‹
                    />
                  </div>
                </div>
                {/* ë‘ ë²ˆì§¸ ê·¸ë¦¬ë“œ ì•„ì´í…œ - í…ìŠ¤íŠ¸ 1fr */}
                <div className={styles.recordingContentReadyGridItem}>
                  <div>
                    <p
                      style={{
                        margin: 0,
                        fontSize: "1rem",
                        fontWeight: "500",
                      }}
                    >
                      ë…¹ìŒì„ ì‹œì‘í•˜ë ¤ë©´ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”
                    </p>
                  </div>
                </div>
                <div className={styles.recordingContentReadyGridItem}>
                  <Button3D
                    variant="main"
                    size="medium"
                    onClick={handleStartRecording}
                  >
                    ğŸ”´ ë…¹ìŒ ì‹œì‘
                  </Button3D>
                </div>
              </div>
            </div>
          </>
        )}

        {/* ì•ˆë‚´ ë©”ì‹œì§€ */}
        <div className={modalStyles.guideSection}>
          <p className={modalStyles.guideText}>
            ğŸ“¢ ë§ˆì´í¬ì— ëŒ€ê³  ëª…í™•í•˜ê²Œ ë°œìŒí•´ì£¼ì„¸ìš”
          </p>
          <p className={modalStyles.guideText}>ìµœëŒ€ 30ì´ˆê¹Œì§€ ë…¹ìŒ ê°€ëŠ¥í•©ë‹ˆë‹¤</p>
        </div>
      </motion.div>
    </>
  );
}
